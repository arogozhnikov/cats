{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from load_problems import load_problem_flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainX, testX, trainY, testY = load_problem_flight(large=True, convert_to_ints=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = load_problem_flight(large=True, convert_to_ints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX.ix[:, 'zeros'] = numpy.zeros(len(trainX), dtype=int)\n",
    "testX.ix[:, 'zeros'] = numpy.zeros(len(testX), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>zeros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>149</td>\n",
       "      <td>157</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>80</td>\n",
       "      <td>198</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>216</td>\n",
       "      <td>155</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Month  DayofMonth  DayOfWeek  DepTime  UniqueCarrier  Origin  Dest  \\\n",
       "0      8           3          4        0             15      37    29   \n",
       "1      6          16          3        8              1     149   157   \n",
       "2      3          13          7        0             13      29    37   \n",
       "3     11          27          6        4             14      80   198   \n",
       "4      7          19          2        1             12     216   155   \n",
       "\n",
       "   Distance  zeros  \n",
       "0         1      0  \n",
       "1         9      0  \n",
       "2         1      0  \n",
       "3         7      0  \n",
       "4         9      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainX['answer'] = trainY\n",
    "\n",
    "# grouping = trainX[:100000].groupby(['Origin', 'Dest', 'UniqueCarrier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hep_ml.losses import LogLossFunction\n",
    "from scipy.special import expit\n",
    "\n",
    "class CategoricalNN:\n",
    "    def __init__(self, n_units=10, regularization=100., batch_size=50000, n_iterations=10, lrate=1.0):\n",
    "        self.n_units = n_units\n",
    "        self.n_iterations = n_iterations\n",
    "        self.regularization = regularization\n",
    "        self.batch_size = batch_size\n",
    "        self.lrate = lrate\n",
    "        \n",
    "    def get_batch_slice(self, X_cat, batch):\n",
    "        start = numpy.random.randint(0, len(X_cat) - batch + 1)\n",
    "        return slice(start, start + batch)\n",
    "        \n",
    "    def fit(self, X_cat, y):\n",
    "        X_cat = numpy.array(X_cat)\n",
    "        self.unit_weights = numpy.random.normal(size=self.n_units)\n",
    "        self.cat_biases = []\n",
    "        self.cat_weights = []\n",
    "        for column in X_cat.T:\n",
    "            self.cat_biases.append(numpy.random.normal(size=[numpy.max(column) + 1]) * 0.1)\n",
    "            self.cat_weights.append(numpy.random.normal(size=[numpy.max(column) + 1, self.n_units]) * 0.1)\n",
    "            \n",
    "        batch = min(self.batch_size, len(X_cat))\n",
    "        \n",
    "        # Training process\n",
    "        for iteration in range(self.n_iterations):\n",
    "            batch_slice = self.get_batch_slice(X_cat, batch)\n",
    "            print batch_slice\n",
    "            self.make_step(X_cat[batch_slice], y[batch_slice], iteration)\n",
    "                   \n",
    "        return self\n",
    "    \n",
    "    def make_step(self, X_cat, y, iteration):\n",
    "        loss = LogLossFunction()\n",
    "        loss.fit(X_cat, y, y * 0 + 1.)\n",
    "        unit_predictions, predictions = self.compute_all(X_cat)\n",
    "        \n",
    "        for column in range(X_cat.shape[1]):\n",
    "            inds = X_cat[:, column]\n",
    "            max_cats = self.cat_biases[column].shape[0]\n",
    "\n",
    "            grads = loss.negative_gradient(predictions)\n",
    "            hesss = loss.hessian(predictions)\n",
    "            nominator = numpy.bincount(inds, weights=grads, minlength=max_cats)\n",
    "            nominator -= self.regularization * self.cat_biases[column]\n",
    "            bias_steps =  nominator/ \\\n",
    "                (numpy.bincount(inds, weights=hesss, minlength=max_cats) + self.regularization)\n",
    "            predictions += bias_steps[inds]\n",
    "            self.cat_biases[column] += bias_steps\n",
    "\n",
    "        for unit in range(self.n_units):\n",
    "            for column in range(X_cat.shape[1]):\n",
    "                inds = X_cat[:, column]\n",
    "                unit_outputs, unit_derivs, unit_hesss = self.act_grad_hess(unit_predictions[:, unit])\n",
    "\n",
    "                unit_weight = self.unit_weights[unit]\n",
    "                grads = loss.negative_gradient(predictions) * unit_weight\n",
    "                hesss = loss.hessian(predictions) * unit_weight ** 2\n",
    "\n",
    "                cat_grads = grads * unit_derivs\n",
    "                cat_hesss = hesss * (unit_derivs ** 2) + grads * unit_hesss\n",
    "\n",
    "                max_cats = self.cat_weights[column].shape[0]\n",
    "\n",
    "                nominator = numpy.bincount(inds, weights=cat_grads, minlength=max_cats)\n",
    "                nominator -= self.regularization * self.cat_weights[column][:, unit]\n",
    "\n",
    "                cat_steps =  nominator/ \\\n",
    "                    (numpy.bincount(inds, weights=cat_hesss.clip(0), minlength=max_cats) + self.regularization)\n",
    "                cat_steps *= self.lrate\n",
    "\n",
    "                unit_outputs = self.activation(unit_predictions[:, unit])\n",
    "                predictions -= self.unit_weights[unit] * unit_outputs\n",
    "                self.cat_weights[column][:, unit] += cat_steps\n",
    "                unit_predictions[:, unit] += cat_steps[inds]\n",
    "                unit_outputs = self.activation(unit_predictions[:, unit])\n",
    "                predictions += self.unit_weights[unit] * unit_outputs\n",
    "\n",
    "            # updating coefficient for unit\n",
    "            for updated_unit in [unit]:\n",
    "                grads = loss.negative_gradient(predictions)\n",
    "                hesss = loss.hessian(predictions)\n",
    "                unit_outputs = self.activation(unit_predictions[:, updated_unit])\n",
    "                nom = numpy.dot(grads, unit_outputs)\n",
    "                denom = (numpy.dot(hesss, unit_outputs ** 2) + self.regularization)\n",
    "                step = 0.5 * nom / denom\n",
    "                self.unit_weights[updated_unit] += step\n",
    "                predictions += step * unit_outputs\n",
    "                \n",
    "            print iteration, unit, loss(predictions)\n",
    "\n",
    "            new_unit_predictions, new_predictions = self.compute_all(X_cat)\n",
    "        assert numpy.allclose(predictions, new_predictions)\n",
    "        assert numpy.allclose(unit_predictions, new_unit_predictions)\n",
    "\n",
    "    \n",
    "#     def activation(self, unit_input):\n",
    "#         return numpy.tanh(unit_input)\n",
    "    \n",
    "#     def act_grad_hess(self, unit_input):\n",
    "#         unit_outputs = numpy.tanh(unit_input)\n",
    "#         unit_derivs =  (1 - unit_outputs ** 2)\n",
    "#         unit_hesss =  - 2 * unit_outputs * unit_derivs        \n",
    "#         return unit_outputs, unit_derivs, unit_hesss\n",
    "    \n",
    "    def activation(self, unit_input):\n",
    "        return unit_input ** 2\n",
    "    \n",
    "    def act_grad_hess(self, unit_input):\n",
    "        unit_outputs = unit_input ** 2\n",
    "        unit_derivs =  2 * unit_input \n",
    "        unit_hesss =   2. + 0 * unit_input\n",
    "        return unit_outputs, unit_derivs, unit_hesss\n",
    "    \n",
    "#     def activation(self, unit_input):\n",
    "#         return numpy.logaddexp(0, unit_input)\n",
    "    \n",
    "#     def act_grad_hess(self, unit_input):\n",
    "#         unit_outputs = numpy.logaddexp(0, unit_input)\n",
    "#         unit_derivs =  expit(unit_input)\n",
    "#         unit_hesss =   unit_derivs * (1. - unit_derivs)\n",
    "#         return unit_outputs, unit_derivs, unit_hesss\n",
    "    \n",
    "    def compute_all(self, X_cat):\n",
    "        X_cat = numpy.array(X_cat)\n",
    "        unit_predictions = numpy.zeros([len(X_cat), self.n_units])\n",
    "        for column, column_weights in enumerate(self.cat_weights):\n",
    "            for unit in range(self.n_units):\n",
    "                unit_predictions[:, unit] += column_weights[X_cat[:, column], unit]\n",
    "        predictions = self.activation(unit_predictions).dot(self.unit_weights)\n",
    "        for column, column_weights in enumerate(self.cat_biases):\n",
    "            predictions += column_weights[X_cat[:, column]]\n",
    "        return unit_predictions, predictions\n",
    "    \n",
    "    def decision_function(self, X_cat):\n",
    "        unit_predictions, predictions = self.compute_all(X_cat)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# x = numpy.array([1, 2, 3])\n",
    "# print (expit(x + 1e-4) - expit(x)) * 1e4\n",
    "# print expit(x) * (1 - expit(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# unit_predictions, predictions = clf.compute_all(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for column in clf.activation(unit_predictions).T:\n",
    "# for column in unit_predictions.T:\n",
    "#     hist(column)\n",
    "#     show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trainX.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = CategoricalNN(n_units=30, regularization=100., n_iterations=100, batch_size=1000000, lrate=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice(4610610, 5610610, None)\n",
      "0 0 663763.997497\n",
      "0 1 663668.533605\n",
      "0 2 655614.681279\n",
      "0 3 654599.881558\n",
      "0 4 652587.274424\n",
      "0 5 651789.766696\n",
      "0 6 648670.789061\n",
      "0 7 648188.019143\n",
      "0 8 647476.55002\n",
      "0 9 647272.286132\n",
      "0 10 646871.338525\n",
      "0 11 645700.303163\n",
      "0 12 644712.868242\n",
      "0 13 644619.43853\n",
      "0 14 643222.226464\n",
      "0 15 638811.743402\n",
      "0 16 638683.168135\n",
      "0 17 637585.313417\n",
      "0 18 635699.76317\n",
      "0 19 635548.87921\n",
      "0 20 634763.191386\n",
      "0 21 633755.868729\n",
      "0 22 631267.384467\n",
      "0 23 631042.508151\n",
      "0 24 630655.390601\n",
      "0 25 627222.574157\n",
      "0 26 626809.018041\n",
      "0 27 626012.034776\n",
      "0 28 625531.268311\n",
      "0 29 625201.815954\n",
      "slice(4856050, 5856050, None)\n",
      "1 0 624859.591586\n",
      "1 1 624792.389356\n",
      "1 2 623348.203868\n",
      "1 3 622919.431582\n",
      "1 4 622326.359071\n",
      "1 5 621980.524472\n",
      "1 6 621103.218445\n",
      "1 7 620817.273764\n",
      "1 8 620572.705972\n",
      "1 9 620398.122626\n",
      "1 10 620173.407685\n",
      "1 11 619742.278765\n",
      "1 12 619460.758659\n",
      "1 13 619359.055688\n",
      "1 14 618818.234892\n",
      "1 15 617930.477337\n",
      "1 16 617818.509527\n",
      "1 17 617433.029541\n",
      "1 18 616846.187435\n",
      "1 19 616767.175935\n",
      "1 20 616481.957083\n",
      "1 21 616096.376985\n",
      "1 22 615308.399816\n",
      "1 23 615136.923951\n",
      "1 24 614950.581378\n",
      "1 25 614209.862594\n",
      "1 26 613982.419716\n",
      "1 27 613629.259235\n",
      "1 28 613492.225637\n",
      "1 29 613312.52171\n",
      "slice(1570276, 2570276, None)\n",
      "2 0 616152.805548\n",
      "2 1 616071.96824\n",
      "2 2 615382.996684\n",
      "2 3 615048.970919\n",
      "2 4 614707.297782\n",
      "2 5 614397.774421\n",
      "2 6 613875.635336\n",
      "2 7 613634.040469\n",
      "2 8 613465.735712\n",
      "2 9 613284.350808\n",
      "2 10 613065.925393\n",
      "2 11 612788.153073\n",
      "2 12 612575.53349\n",
      "2 13 612452.225361\n",
      "2 14 612147.644115\n",
      "2 15 611719.229944\n",
      "2 16 611598.066046\n",
      "2 17 611292.237459\n",
      "2 18 610954.516763\n",
      "2 19 610876.188117\n",
      "2 20 610682.436091\n",
      "2 21 610420.907738\n",
      "2 22 609998.098837\n",
      "2 23 609846.643555\n",
      "2 24 609701.7345\n",
      "2 25 609280.526657\n",
      "2 26 609082.756298\n",
      "2 27 608827.929452\n",
      "2 28 608691.897288\n",
      "2 29 608533.228959\n",
      "slice(7228102, 8228102, None)\n",
      "3 0 611027.62201\n",
      "3 1 610946.028731\n",
      "3 2 610536.529148\n",
      "3 3 610263.932149\n",
      "3 4 610005.816152\n",
      "3 5 609739.87809\n",
      "3 6 609384.770769\n",
      "3 7 609198.249452\n",
      "3 8 609066.430046\n",
      "3 9 608883.391051\n",
      "3 10 608664.166844\n",
      "3 11 608418.863384\n",
      "3 12 608266.099173\n",
      "3 13 608137.153748\n",
      "3 14 607908.145791\n",
      "3 15 607609.664219\n",
      "3 16 607493.737423\n",
      "3 17 607252.87191\n",
      "3 18 607023.479991\n",
      "3 19 606951.169313\n",
      "3 20 606831.655847\n",
      "3 21 606635.215926\n",
      "3 22 606406.472085\n",
      "3 23 606289.312957\n",
      "3 24 606170.360903\n",
      "3 25 605840.432406\n",
      "3 26 605666.097751\n",
      "3 27 605502.596265\n",
      "3 28 605354.440863\n",
      "3 29 605201.773799\n",
      "slice(4272995, 5272995, None)\n",
      "4 0 605159.562092\n",
      "4 1 605058.444363\n",
      "4 2 604778.711529\n",
      "4 3 604521.19606\n",
      "4 4 604294.950507\n",
      "4 5 604076.145501\n",
      "4 6 603773.146577\n",
      "4 7 603568.040199\n",
      "4 8 603430.705577\n",
      "4 9 603272.242395\n",
      "4 10 603081.536814\n",
      "4 11 602891.763848\n",
      "4 12 602787.479362\n",
      "4 13 602645.138574\n",
      "4 14 602485.817072\n",
      "4 15 602244.067908\n",
      "4 16 602129.636237\n",
      "4 17 601943.039696\n",
      "4 18 601782.505772\n",
      "4 19 601703.327535\n",
      "4 20 601598.749176\n",
      "4 21 601443.924567\n",
      "4 22 601250.629671\n",
      "4 23 601131.907026\n",
      "4 24 601045.645771\n",
      "4 25 600764.485921\n",
      "4 26 600623.821028\n",
      "4 27 600488.57706\n",
      "4 28 600352.279061\n",
      "4 29 600217.66991\n",
      "slice(1590084, 2590084, None)\n",
      "5 0 601444.677425\n",
      "5 1 601340.254163\n",
      "5 2 601100.145122\n",
      "5 3 600880.133897\n",
      "5 4 600697.606619\n",
      "5 5 600503.221865\n",
      "5 6 600231.470008\n",
      "5 7 600041.051505\n",
      "5 8 599916.448829\n",
      "5 9 599746.677619\n",
      "5 10 599559.221298\n",
      "5 11 599395.059728\n",
      "5 12 599281.40501\n",
      "5 13 599152.968072\n",
      "5 14 599020.75691\n",
      "5 15 598836.101485\n",
      "5 16 598729.595539\n",
      "5 17 598554.992167\n",
      "5 18 598418.391027\n",
      "5 19 598340.130373\n",
      "5 20 598242.968026\n",
      "5 21 598115.152016\n",
      "5 22 597961.399651\n",
      "5 23 597862.808809\n",
      "5 24 597768.171177\n",
      "5 25 597524.003229\n",
      "5 26 597380.147117\n",
      "5 27 597275.702296\n",
      "5 28 597123.84549\n",
      "5 29 597006.16525\n",
      "slice(2403358, 3403358, None)\n",
      "6 0 598639.009574\n",
      "6 1 598544.65006\n",
      "6 2 598338.948811\n",
      "6 3 598126.708929\n",
      "6 4 597963.170761\n",
      "6 5 597801.474357\n",
      "6 6 597590.425444\n",
      "6 7 597420.696866\n",
      "6 8 597311.697101\n",
      "6 9 597155.811429\n",
      "6 10 596966.425114\n",
      "6 11 596777.739107\n",
      "6 12 596671.001637\n",
      "6 13 596545.995064\n",
      "6 14 596424.176887\n",
      "6 15 596254.897529\n",
      "6 16 596165.908933\n",
      "6 17 596032.021413\n",
      "6 18 595895.593501\n",
      "6 19 595812.233556\n",
      "6 20 595730.366299\n",
      "6 21 595595.056469\n",
      "6 22 595449.691627\n",
      "6 23 595346.451793\n",
      "6 24 595261.261015\n",
      "6 25 595060.207142\n",
      "6 26 594937.629988\n",
      "6 27 594830.562793\n",
      "6 28 594679.433991\n",
      "6 29 594567.152783\n",
      "slice(8276927, 9276927, None)\n",
      "7 0 598336.425987\n",
      "7 1 598239.703126\n",
      "7 2 598040.212015\n",
      "7 3 597822.744687\n",
      "7 4 597671.734564\n",
      "7 5 597526.419316\n",
      "7 6 597301.075792\n",
      "7 7 597144.356591\n",
      "7 8 597026.452365\n",
      "7 9 596874.626313\n",
      "7 10 596695.208244\n",
      "7 11 596518.036803\n",
      "7 12 596409.373412\n",
      "7 13 596286.728563\n",
      "7 14 596163.478646\n",
      "7 15 596009.025537\n",
      "7 16 595927.623643\n",
      "7 17 595799.510207\n",
      "7 18 595667.631196\n",
      "7 19 595591.483004\n",
      "7 20 595501.724132\n",
      "7 21 595379.186217\n",
      "7 22 595227.696405\n",
      "7 23 595135.905707\n",
      "7 24 595051.848103\n",
      "7 25 594844.582703\n",
      "7 26 594713.895629\n",
      "7 27 594602.305988\n",
      "7 28 594465.276203\n",
      "7 29 594362.815536\n",
      "slice(2128886, 3128886, None)\n",
      "8 0 593395.857792\n",
      "8 1 593311.645253\n",
      "8 2 593159.904776\n",
      "8 3 593004.565217\n",
      "8 4 592873.372819\n",
      "8 5 592752.565138\n",
      "8 6 592602.892142\n",
      "8 7 592464.968951\n",
      "8 8 592369.883445\n",
      "8 9 592228.048532\n",
      "8 10 592092.041949\n",
      "8 11 591947.497978\n",
      "8 12 591858.487238\n",
      "8 13 591774.083016\n",
      "8 14 591690.156397\n",
      "8 15 591564.405276\n",
      "8 16 591487.32061\n",
      "8 17 591373.239919\n",
      "8 18 591276.142387\n",
      "8 19 591199.494915\n",
      "8 20 591136.74417\n",
      "8 21 591034.028241\n",
      "8 22 590932.624142\n",
      "8 23 590849.233531\n",
      "8 24 590765.299435\n",
      "8 25 590623.935616\n",
      "8 26 590521.215921\n",
      "8 27 590437.746792\n",
      "8 28 590299.982459\n",
      "8 29 590211.103745\n",
      "slice(8511637, 9511637, None)\n",
      "9 0 593853.679024\n",
      "9 1 593769.830607\n",
      "9 2 593620.761858\n",
      "9 3 593449.527997\n",
      "9 4 593313.487786\n",
      "9 5 593199.760967\n",
      "9 6 593036.896241\n",
      "9 7 592904.965909\n",
      "9 8 592805.735104\n",
      "9 9 592679.834576\n",
      "9 10 592540.968137\n",
      "9 11 592401.148722\n",
      "9 12 592305.443914\n",
      "9 13 592207.427876\n",
      "9 14 592117.463722\n",
      "9 15 591992.625304\n",
      "9 16 591922.29151\n",
      "9 17 591805.551465\n",
      "9 18 591706.965274\n",
      "9 19 591631.066925\n",
      "9 20 591549.068298\n",
      "9 21 591440.735739\n",
      "9 22 591313.974434\n",
      "9 23 591226.404445\n",
      "9 24 591159.098763\n",
      "9 25 591006.424524\n",
      "9 26 590899.272252\n",
      "9 27 590809.491812\n",
      "9 28 590682.588739\n",
      "9 29 590585.037927\n",
      "slice(714481, 1714481, None)\n",
      "10 0 592656.946034\n",
      "10 1 592554.055368\n",
      "10 2 592356.571544\n",
      "10 3 592154.079416\n",
      "10 4 592001.737049\n",
      "10 5 591889.198161\n",
      "10 6 591740.595022\n",
      "10 7 591592.762329\n",
      "10 8 591490.99636\n",
      "10 9 591348.257649\n",
      "10 10 591212.081808\n",
      "10 11 591053.279385\n",
      "10 12 590943.890183\n",
      "10 13 590839.329529\n",
      "10 14 590738.140789\n",
      "10 15 590591.61337\n",
      "10 16 590512.706642\n",
      "10 17 590376.481346\n",
      "10 18 590257.158953\n",
      "10 19 590178.408643\n",
      "10 20 590099.028678\n",
      "10 21 589968.137647\n",
      "10 22 589841.942423\n",
      "10 23 589749.097274\n",
      "10 24 589671.896315\n",
      "10 25 589524.385891\n",
      "10 26 589405.09376\n",
      "10 27 589317.481642\n",
      "10 28 589190.421855\n",
      "10 29 589091.529147\n",
      "slice(7136664, 8136664, None)\n",
      "11 0 592173.633919\n",
      "11 1 592080.729857\n",
      "11 2 591907.106237\n",
      "11 3 591748.528215\n",
      "11 4 591613.587615\n",
      "11 5 591491.921779\n",
      "11 6 591352.169235\n",
      "11 7 591222.553221\n",
      "11 8 591123.31342\n",
      "11 9 590974.720974\n",
      "11 10 590812.320751\n",
      "11 11 590684.677935\n",
      "11 12 590575.063021\n",
      "11 13 590479.257582\n",
      "11 14 590386.436551\n",
      "11 15 590250.352482\n",
      "11 16 590168.176604\n",
      "11 17 590052.088181\n",
      "11 18 589937.314156\n",
      "11 19 589859.0568\n",
      "11 20 589781.208611\n",
      "11 21 589663.18928\n",
      "11 22 589546.185516\n",
      "11 23 589461.752266\n",
      "11 24 589375.972721\n",
      "11 25 589225.00833\n",
      "11 26 589124.708052\n",
      "11 27 589044.653964\n",
      "11 28 588917.929027\n",
      "11 29 588826.795716\n",
      "slice(3137324, 4137324, None)\n",
      "12 0 590687.943247\n",
      "12 1 590576.604832\n",
      "12 2 590403.14425\n",
      "12 3 590235.023423\n",
      "12 4 590090.77897\n",
      "12 5 589975.522613\n",
      "12 6 589832.415069\n",
      "12 7 589705.091148\n",
      "12 8 589603.092812\n",
      "12 9 589450.046152\n",
      "12 10 589306.247095\n",
      "12 11 589173.669643\n",
      "12 12 589071.499573\n",
      "12 13 588969.275134\n",
      "12 14 588881.366239\n",
      "12 15 588747.576035\n",
      "12 16 588669.610675\n",
      "12 17 588562.815812\n",
      "12 18 588448.936253\n",
      "12 19 588366.40327\n",
      "12 20 588285.04557\n",
      "12 21 588178.656309\n",
      "12 22 588059.334501\n",
      "12 23 587970.680745\n",
      "12 24 587897.613383\n",
      "12 25 587769.444486\n",
      "12 26 587671.109212\n",
      "12 27 587589.368648\n",
      "12 28 587451.792879\n",
      "12 29 587360.097482\n",
      "slice(2625621, 3625621, None)\n",
      "13 0 587879.592872\n",
      "13 1 587795.799333\n",
      "13 2 587693.945996\n",
      "13 3 587564.924737\n",
      "13 4 587467.9461\n",
      "13 5 587376.668032\n",
      "13 6 587277.714183\n",
      "13 7 587191.074253\n",
      "13 8 587106.086691\n",
      "13 9 586993.775395\n",
      "13 10 586875.517098\n",
      "13 11 586764.378378\n",
      "13 12 586673.596011\n",
      "13 13 586589.585994\n",
      "13 14 586527.388864\n",
      "13 15 586426.8614\n",
      "13 16 586361.698881\n",
      "13 17 586275.228585\n",
      "13 18 586194.03306\n",
      "13 19 586121.685217\n",
      "13 20 586054.720094\n",
      "13 21 585956.372965\n",
      "13 22 585859.92006\n",
      "13 23 585783.45475\n",
      "13 24 585726.496488\n",
      "13 25 585625.954194\n",
      "13 26 585551.352161\n",
      "13 27 585483.435855\n",
      "13 28 585371.433723\n",
      "13 29 585299.69336\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-b2bc344f7efe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-2cc642fda5ff>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_cat, y)\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mbatch_slice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_batch_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_cat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[0mbatch_slice\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_cat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_slice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_slice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-2cc642fda5ff>\u001b[0m in \u001b[0;36mmake_step\u001b[1;34m(self, X_cat, y, iteration)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0mnew_unit_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_cat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munit_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_unit_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-2cc642fda5ff>\u001b[0m in \u001b[0;36mcompute_all\u001b[1;34m(self, X_cat)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_weights\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0munit\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_units\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m                 \u001b[0munit_predictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munit\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcolumn_weights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_cat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munit\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munit_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munit_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_weights\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat_biases\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.CategoricalNN instance at 0x7f23e57fd7e8>\n",
      "0.751087133865\n",
      "0.720943905257\n"
     ]
    }
   ],
   "source": [
    "print clf\n",
    "print roc_auc_score(trainY, clf.decision_function(trainX))\n",
    "print roc_auc_score(testY,  clf.decision_function(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.CategoricalNN instance at 0x7f568f2afe60>\n",
      "0.735934133778\n",
      "0.721468011263\n"
     ]
    }
   ],
   "source": [
    "print clf\n",
    "print roc_auc_score(trainY, clf.decision_function(trainX))\n",
    "print roc_auc_score(testY, clf.decision_function(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.CategoricalNN instance at 0x7f568f2c95f0>\n",
      "0.738086474224\n",
      "0.721193077929\n"
     ]
    }
   ],
   "source": [
    "print clf\n",
    "print roc_auc_score(trainY, clf.decision_function(trainX))\n",
    "print roc_auc_score(testY, clf.decision_function(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.CategoricalNN instance at 0x7f568f2c9170>\n",
      "0.731771269637\n",
      "0.72065038133\n"
     ]
    }
   ],
   "source": [
    "print clf\n",
    "print roc_auc_score(trainY, clf.decision_function(trainX))\n",
    "print roc_auc_score(testY, clf.decision_function(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.CategoricalNN instance at 0x7f56aecf4248>\n",
      "0.740230209945\n",
      "0.720767266292\n"
     ]
    }
   ],
   "source": [
    "print clf\n",
    "print roc_auc_score(trainY, clf.decision_function(trainX))\n",
    "print roc_auc_score(testY, clf.decision_function(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.CategoricalNN instance at 0x7f208f4667a0>\n",
      "0.735496912711\n",
      "0.718110408177\n"
     ]
    }
   ],
   "source": [
    "print clf\n",
    "print roc_auc_score(trainY, clf.decision_function(trainX))\n",
    "print roc_auc_score(testY, clf.decision_function(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.CategoricalNN instance at 0x7f625e4b0cf8>\n",
      "0.754232554815\n",
      "0.723084829554\n"
     ]
    }
   ],
   "source": [
    "# 30 units, 15 iters\n",
    "\n",
    "print clf\n",
    "print roc_auc_score(trainY, clf.decision_function(trainX))\n",
    "print roc_auc_score(testY, clf.decision_function(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.CategoricalNN instance at 0x7f625e865638>\n",
      "0.742562118649\n",
      "0.724197014453\n"
     ]
    }
   ],
   "source": [
    "# 30 units, 10 iters\n",
    "print clf\n",
    "print roc_auc_score(trainY, clf.decision_function(trainX))\n",
    "print roc_auc_score(testY, clf.decision_function(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.CategoricalNN instance at 0x7f625e82c710>\n",
      "0.726788577363\n",
      "0.719745336362\n"
     ]
    }
   ],
   "source": [
    "print clf\n",
    "print roc_auc_score(trainY, clf.decision_function(trainX))\n",
    "print roc_auc_score(testY, clf.decision_function(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.CategoricalNN instance at 0x7f625e82c710>\n",
      "0.726788577363\n",
      "0.719745336362\n"
     ]
    }
   ],
   "source": [
    "print clf\n",
    "print roc_auc_score(trainY, clf.decision_function(trainX))\n",
    "print roc_auc_score(testY, clf.decision_function(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73466349043\n",
      "0.71752045488\n"
     ]
    }
   ],
   "source": [
    "print roc_auc_score(trainY, clf.decision_function(trainX))\n",
    "\n",
    "print roc_auc_score(testY, clf.decision_function(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.724158762186\n",
      "0.719145020432\n"
     ]
    }
   ],
   "source": [
    "print roc_auc_score(trainY, clf.decision_function(trainX))\n",
    "\n",
    "print roc_auc_score(testY, clf.decision_function(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73534970466121707"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print roc_auc_score(trainY, clf.decision_function(trainX))\n",
    "print roc_auc_score(testY, clf.decision_function(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# lengths = []\n",
    "# counter = 0\n",
    "# for a, b in grouping:\n",
    "#     if len(b) > 2:\n",
    "#         print a\n",
    "#         print b.sort('DepTime')\n",
    "#         counter += 1\n",
    "#         if counter > 40:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lengths[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(trainX)\n",
    "trainX2 = encoder.transform(trainX)\n",
    "testX2 = encoder.transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.fit(trainX2, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(testX2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(testY, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashes = numpy.bitwise_xor(trainX.DayOfWeek.map(hash), trainX.UniqueCarrier.map(hash) + trainX.Distance.map(hash))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positives = numpy.bincount(hashes % 100000, weights=trainY)\n",
    "negatives = numpy.bincount(hashes % 100000, weights=1 - trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainX.sort()\n",
    "# hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
